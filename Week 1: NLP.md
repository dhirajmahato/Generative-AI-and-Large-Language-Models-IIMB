# Natural Language Processing
- Text data is considered **sequential data**, so _different architecture to handle it_
- We use sequential models such as RNNs that is Recurrent Neural Networks for that. Within RNNs there are different variants such as LSTM that is Long Short Term Memory, and GRU that is Gated Recurrent Unit.

## NLP pipeline
1. Preproecessing:
     - **Text**:(tokenization, stopword removal, stemming/Lemmatization,..)
     - **Linguistic**: (POS tagging, NER, chunking..)
2. Text Representation
    - TF-IDF
    - Word embedding
    - Positional embedding
    - Contextual embedding 
   
